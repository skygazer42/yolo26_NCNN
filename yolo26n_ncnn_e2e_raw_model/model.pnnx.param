7767517
283 296
pnnx.Input               pnnx_input_0             0 1 0 #0=(1,3,640,640)f32
nn.Conv2d                model.0.conv             1 1 0 1 bias=True dilation=(1,1) groups=1 in_channels=3 kernel_size=(3,3) out_channels=16 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(16)f32 @weight=(16,3,3,3)f32 #0=(1,3,640,640)f32 #1=(1,16,320,320)f32
nn.SiLU                  model.22.m.0.1.ffn.0.act 1 1 1 2 #1=(1,16,320,320)f32 #2=(1,16,320,320)f32
nn.Conv2d                model.1.conv             1 1 2 3 bias=True dilation=(1,1) groups=1 in_channels=16 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(32)f32 @weight=(32,16,3,3)f32 #2=(1,16,320,320)f32 #3=(1,32,160,160)f32
nn.SiLU                  pnnx_unique_0            1 1 3 4 #3=(1,32,160,160)f32 #4=(1,32,160,160)f32
nn.Conv2d                model.2.cv1.conv         1 1 4 5 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(1,1) out_channels=32 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,32,1,1)f32 #4=(1,32,160,160)f32 #5=(1,32,160,160)f32
nn.SiLU                  pnnx_unique_1            1 1 5 6 #5=(1,32,160,160)f32 #6=(1,32,160,160)f32
torch.chunk              torch.chunk_65           1 2 6 7 8 chunks=2 dim=1 $input=6 #6=(1,32,160,160)f32 #7=(1,16,160,160)f32 #8=(1,16,160,160)f32
nn.Conv2d                model.2.m.0.cv1.conv     1 1 8 9 bias=True dilation=(1,1) groups=1 in_channels=16 kernel_size=(3,3) out_channels=8 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(8)f32 @weight=(8,16,3,3)f32 #8=(1,16,160,160)f32 #9=(1,8,160,160)f32
nn.SiLU                  pnnx_unique_2            1 1 9 10 #9=(1,8,160,160)f32 #10=(1,8,160,160)f32
nn.Conv2d                model.2.m.0.cv2.conv     1 1 10 11 bias=True dilation=(1,1) groups=1 in_channels=8 kernel_size=(3,3) out_channels=16 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(16)f32 @weight=(16,8,3,3)f32 #10=(1,8,160,160)f32 #11=(1,16,160,160)f32
nn.SiLU                  pnnx_unique_3            1 1 11 12 #11=(1,16,160,160)f32 #12=(1,16,160,160)f32
pnnx.Expression          pnnx_expr_232            2 1 8 12 13 expr=add(@0,@1) #8=(1,16,160,160)f32 #12=(1,16,160,160)f32 #13=(1,16,160,160)f32
torch.cat                torch.cat_40             3 1 7 8 13 14 dim=1 #7=(1,16,160,160)f32 #8=(1,16,160,160)f32 #13=(1,16,160,160)f32 #14=(1,48,160,160)f32
nn.Conv2d                model.2.cv2.conv         1 1 14 15 bias=True dilation=(1,1) groups=1 in_channels=48 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,48,1,1)f32 #14=(1,48,160,160)f32 #15=(1,64,160,160)f32
nn.SiLU                  pnnx_unique_4            1 1 15 16 #15=(1,64,160,160)f32 #16=(1,64,160,160)f32
nn.Conv2d                model.3.conv             1 1 16 17 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(64)f32 @weight=(64,64,3,3)f32 #16=(1,64,160,160)f32 #17=(1,64,80,80)f32
nn.SiLU                  pnnx_unique_5            1 1 17 18 #17=(1,64,80,80)f32 #18=(1,64,80,80)f32
nn.Conv2d                model.4.cv1.conv         1 1 18 19 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,1,1)f32 #18=(1,64,80,80)f32 #19=(1,64,80,80)f32
nn.SiLU                  pnnx_unique_6            1 1 19 20 #19=(1,64,80,80)f32 #20=(1,64,80,80)f32
torch.chunk              torch.chunk_66           1 2 20 21 22 chunks=2 dim=1 $input=20 #20=(1,64,80,80)f32 #21=(1,32,80,80)f32 #22=(1,32,80,80)f32
nn.Conv2d                model.4.m.0.cv1.conv     1 1 22 23 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(3,3) out_channels=16 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(16)f32 @weight=(16,32,3,3)f32 #22=(1,32,80,80)f32 #23=(1,16,80,80)f32
nn.SiLU                  pnnx_unique_7            1 1 23 24 #23=(1,16,80,80)f32 #24=(1,16,80,80)f32
nn.Conv2d                model.4.m.0.cv2.conv     1 1 24 25 bias=True dilation=(1,1) groups=1 in_channels=16 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,16,3,3)f32 #24=(1,16,80,80)f32 #25=(1,32,80,80)f32
nn.SiLU                  pnnx_unique_8            1 1 25 26 #25=(1,32,80,80)f32 #26=(1,32,80,80)f32
pnnx.Expression          pnnx_expr_227            2 1 22 26 27 expr=add(@0,@1) #22=(1,32,80,80)f32 #26=(1,32,80,80)f32 #27=(1,32,80,80)f32
torch.cat                torch.cat_41             3 1 21 22 27 28 dim=1 #21=(1,32,80,80)f32 #22=(1,32,80,80)f32 #27=(1,32,80,80)f32 #28=(1,96,80,80)f32
nn.Conv2d                model.4.cv2.conv         1 1 28 29 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,96,1,1)f32 #28=(1,96,80,80)f32 #29=(1,128,80,80)f32
nn.SiLU                  pnnx_unique_9            1 1 29 30 #29=(1,128,80,80)f32 #30=(1,128,80,80)f32
nn.Conv2d                model.5.conv             1 1 30 31 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(128)f32 @weight=(128,128,3,3)f32 #30=(1,128,80,80)f32 #31=(1,128,40,40)f32
nn.SiLU                  pnnx_unique_10           1 1 31 32 #31=(1,128,40,40)f32 #32=(1,128,40,40)f32
nn.Conv2d                model.6.cv1.conv         1 1 32 33 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,1,1)f32 #32=(1,128,40,40)f32 #33=(1,128,40,40)f32
nn.SiLU                  pnnx_unique_11           1 1 33 34 #33=(1,128,40,40)f32 #34=(1,128,40,40)f32
torch.chunk              torch.chunk_67           1 2 34 35 36 chunks=2 dim=1 $input=34 #34=(1,128,40,40)f32 #35=(1,64,40,40)f32 #36=(1,64,40,40)f32
nn.Conv2d                model.6.m.0.cv1.conv     1 1 36 37 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=32 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,64,1,1)f32 #36=(1,64,40,40)f32 #37=(1,32,40,40)f32
nn.SiLU                  pnnx_unique_12           1 1 37 38 #37=(1,32,40,40)f32 #38=(1,32,40,40)f32
nn.Conv2d                model.6.m.0.m.0.cv1.conv 1 1 38 39 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,32,3,3)f32 #38=(1,32,40,40)f32 #39=(1,32,40,40)f32
nn.SiLU                  pnnx_unique_13           1 1 39 40 #39=(1,32,40,40)f32 #40=(1,32,40,40)f32
nn.Conv2d                model.6.m.0.m.0.cv2.conv 1 1 40 41 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,32,3,3)f32 #40=(1,32,40,40)f32 #41=(1,32,40,40)f32
nn.SiLU                  pnnx_unique_14           1 1 41 42 #41=(1,32,40,40)f32 #42=(1,32,40,40)f32
pnnx.Expression          pnnx_expr_221            2 1 38 42 43 expr=add(@0,@1) #38=(1,32,40,40)f32 #42=(1,32,40,40)f32 #43=(1,32,40,40)f32
nn.Conv2d                model.6.m.0.m.1.cv1.conv 1 1 43 44 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,32,3,3)f32 #43=(1,32,40,40)f32 #44=(1,32,40,40)f32
nn.SiLU                  pnnx_unique_15           1 1 44 45 #44=(1,32,40,40)f32 #45=(1,32,40,40)f32
nn.Conv2d                model.6.m.0.m.1.cv2.conv 1 1 45 46 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,32,3,3)f32 #45=(1,32,40,40)f32 #46=(1,32,40,40)f32
nn.SiLU                  pnnx_unique_16           1 1 46 47 #46=(1,32,40,40)f32 #47=(1,32,40,40)f32
pnnx.Expression          pnnx_expr_219            2 1 43 47 48 expr=add(@0,@1) #43=(1,32,40,40)f32 #47=(1,32,40,40)f32 #48=(1,32,40,40)f32
nn.Conv2d                model.6.m.0.cv2.conv     1 1 36 49 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=32 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,64,1,1)f32 #36=(1,64,40,40)f32 #49=(1,32,40,40)f32
nn.SiLU                  pnnx_unique_17           1 1 49 50 #49=(1,32,40,40)f32 #50=(1,32,40,40)f32
torch.cat                torch.cat_42             2 1 48 50 51 dim=1 #48=(1,32,40,40)f32 #50=(1,32,40,40)f32 #51=(1,64,40,40)f32
nn.Conv2d                model.6.m.0.cv3.conv     1 1 51 52 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,1,1)f32 #51=(1,64,40,40)f32 #52=(1,64,40,40)f32
nn.SiLU                  pnnx_unique_18           1 1 52 53 #52=(1,64,40,40)f32 #53=(1,64,40,40)f32
torch.cat                torch.cat_43             3 1 35 36 53 54 dim=1 #35=(1,64,40,40)f32 #36=(1,64,40,40)f32 #53=(1,64,40,40)f32 #54=(1,192,40,40)f32
nn.Conv2d                model.6.cv2.conv         1 1 54 55 bias=True dilation=(1,1) groups=1 in_channels=192 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,192,1,1)f32 #54=(1,192,40,40)f32 #55=(1,128,40,40)f32
nn.SiLU                  pnnx_unique_19           1 1 55 56 #55=(1,128,40,40)f32 #56=(1,128,40,40)f32
nn.Conv2d                model.7.conv             1 1 56 57 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(256)f32 @weight=(256,128,3,3)f32 #56=(1,128,40,40)f32 #57=(1,256,20,20)f32
nn.SiLU                  pnnx_unique_20           1 1 57 58 #57=(1,256,20,20)f32 #58=(1,256,20,20)f32
nn.Conv2d                model.8.cv1.conv         1 1 58 59 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,256,1,1)f32 #58=(1,256,20,20)f32 #59=(1,256,20,20)f32
nn.SiLU                  pnnx_unique_21           1 1 59 60 #59=(1,256,20,20)f32 #60=(1,256,20,20)f32
torch.chunk              torch.chunk_68           1 2 60 61 62 chunks=2 dim=1 $input=60 #60=(1,256,20,20)f32 #61=(1,128,20,20)f32 #62=(1,128,20,20)f32
nn.Conv2d                model.8.m.0.cv1.conv     1 1 62 63 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,128,1,1)f32 #62=(1,128,20,20)f32 #63=(1,64,20,20)f32
nn.SiLU                  pnnx_unique_22           1 1 63 64 #63=(1,64,20,20)f32 #64=(1,64,20,20)f32
nn.Conv2d                model.8.m.0.m.0.cv1.conv 1 1 64 65 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,3,3)f32 #64=(1,64,20,20)f32 #65=(1,64,20,20)f32
nn.SiLU                  pnnx_unique_23           1 1 65 66 #65=(1,64,20,20)f32 #66=(1,64,20,20)f32
nn.Conv2d                model.8.m.0.m.0.cv2.conv 1 1 66 67 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,3,3)f32 #66=(1,64,20,20)f32 #67=(1,64,20,20)f32
nn.SiLU                  pnnx_unique_24           1 1 67 68 #67=(1,64,20,20)f32 #68=(1,64,20,20)f32
pnnx.Expression          pnnx_expr_213            2 1 64 68 69 expr=add(@0,@1) #64=(1,64,20,20)f32 #68=(1,64,20,20)f32 #69=(1,64,20,20)f32
nn.Conv2d                model.8.m.0.m.1.cv1.conv 1 1 69 70 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,3,3)f32 #69=(1,64,20,20)f32 #70=(1,64,20,20)f32
nn.SiLU                  pnnx_unique_25           1 1 70 71 #70=(1,64,20,20)f32 #71=(1,64,20,20)f32
nn.Conv2d                model.8.m.0.m.1.cv2.conv 1 1 71 72 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,3,3)f32 #71=(1,64,20,20)f32 #72=(1,64,20,20)f32
nn.SiLU                  pnnx_unique_26           1 1 72 73 #72=(1,64,20,20)f32 #73=(1,64,20,20)f32
pnnx.Expression          pnnx_expr_211            2 1 69 73 74 expr=add(@0,@1) #69=(1,64,20,20)f32 #73=(1,64,20,20)f32 #74=(1,64,20,20)f32
nn.Conv2d                model.8.m.0.cv2.conv     1 1 62 75 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,128,1,1)f32 #62=(1,128,20,20)f32 #75=(1,64,20,20)f32
nn.SiLU                  pnnx_unique_27           1 1 75 76 #75=(1,64,20,20)f32 #76=(1,64,20,20)f32
torch.cat                torch.cat_44             2 1 74 76 77 dim=1 #74=(1,64,20,20)f32 #76=(1,64,20,20)f32 #77=(1,128,20,20)f32
nn.Conv2d                model.8.m.0.cv3.conv     1 1 77 78 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,1,1)f32 #77=(1,128,20,20)f32 #78=(1,128,20,20)f32
nn.SiLU                  pnnx_unique_28           1 1 78 79 #78=(1,128,20,20)f32 #79=(1,128,20,20)f32
torch.cat                torch.cat_45             3 1 61 62 79 80 dim=1 #61=(1,128,20,20)f32 #62=(1,128,20,20)f32 #79=(1,128,20,20)f32 #80=(1,384,20,20)f32
nn.Conv2d                model.8.cv2.conv         1 1 80 81 bias=True dilation=(1,1) groups=1 in_channels=384 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,384,1,1)f32 #80=(1,384,20,20)f32 #81=(1,256,20,20)f32
nn.SiLU                  pnnx_unique_29           1 1 81 82 #81=(1,256,20,20)f32 #82=(1,256,20,20)f32
nn.Conv2d                model.9.cv1.conv         1 1 82 83 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,256,1,1)f32 #82=(1,256,20,20)f32 #83=(1,128,20,20)f32
nn.MaxPool2d             model.9.m                1 1 83 84 ceil_mode=False dilation=(1,1) kernel_size=(5,5) padding=(2,2) return_indices=False stride=(1,1) #83=(1,128,20,20)f32 #84=(1,128,20,20)f32
nn.MaxPool2d             pnnx_unique_30           1 1 84 85 ceil_mode=False dilation=(1,1) kernel_size=(5,5) padding=(2,2) return_indices=False stride=(1,1) #84=(1,128,20,20)f32 #85=(1,128,20,20)f32
nn.MaxPool2d             pnnx_unique_31           1 1 85 86 ceil_mode=False dilation=(1,1) kernel_size=(5,5) padding=(2,2) return_indices=False stride=(1,1) #85=(1,128,20,20)f32 #86=(1,128,20,20)f32
torch.cat                torch.cat_46             4 1 83 84 85 86 87 dim=1 #83=(1,128,20,20)f32 #84=(1,128,20,20)f32 #85=(1,128,20,20)f32 #86=(1,128,20,20)f32 #87=(1,512,20,20)f32
nn.Conv2d                model.9.cv2.conv         1 1 87 88 bias=True dilation=(1,1) groups=1 in_channels=512 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,512,1,1)f32 #87=(1,512,20,20)f32 #88=(1,256,20,20)f32
nn.SiLU                  pnnx_unique_32           1 1 88 89 #88=(1,256,20,20)f32 #89=(1,256,20,20)f32
pnnx.Expression          pnnx_expr_207            2 1 89 82 90 expr=add(@0,@1) #89=(1,256,20,20)f32 #82=(1,256,20,20)f32 #90=(1,256,20,20)f32
nn.Conv2d                model.10.cv1.conv        1 1 90 91 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,256,1,1)f32 #90=(1,256,20,20)f32 #91=(1,256,20,20)f32
nn.SiLU                  pnnx_unique_33           1 1 91 92 #91=(1,256,20,20)f32 #92=(1,256,20,20)f32
torch.split              torch.split_74           1 2 92 93 94 dim=1 split_size_or_sections=(128,128) $tensor=92 #92=(1,256,20,20)f32 #93=(1,128,20,20)f32 #94=(1,128,20,20)f32
nn.Conv2d                model.10.m.0.attn.qkv.conv 1 1 94 95 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,128,1,1)f32 #94=(1,128,20,20)f32 #95=(1,256,20,20)f32
Tensor.view              Tensor.view_27           1 1 95 96 shape=(1,2,128,400) $input=95 #95=(1,256,20,20)f32 #96=(1,2,128,400)f32
torch.split              torch.split_75           1 3 96 97 98 99 dim=2 split_size_or_sections=(32,32,64) $tensor=96 #96=(1,2,128,400)f32 #97=(1,2,32,400)f32 #98=(1,2,32,400)f32 #99=(1,2,64,400)f32
torch.transpose          torch.transpose_80       1 1 97 100 dim0=-2 dim1=-1 $input=97 #97=(1,2,32,400)f32 #100=(1,2,400,32)f32
torch.matmul             torch.matmul_90          2 1 100 98 101 $input=100 $other=98 #100=(1,2,400,32)f32 #98=(1,2,32,400)f32 #101=(1,2,400,400)f32
pnnx.Expression          pnnx_expr_183            1 1 101 102 expr=mul(@0,0.17677669) #101=(1,2,400,400)f32 #102=(1,2,400,400)f32
F.softmax                F.softmax_95             1 1 102 103 dim=-1 $input=102 #102=(1,2,400,400)f32 #103=(1,2,400,400)f32
torch.transpose          torch.transpose_81       1 1 103 104 dim0=-2 dim1=-1 $input=103 #103=(1,2,400,400)f32 #104=(1,2,400,400)f32
torch.matmul             torch.matmul_91          2 1 99 104 105 $input=99 $other=104 #99=(1,2,64,400)f32 #104=(1,2,400,400)f32 #105=(1,2,64,400)f32
Tensor.view              Tensor.view_28           1 1 105 106 shape=(1,128,20,20) $input=105 #105=(1,2,64,400)f32 #106=(1,128,20,20)f32
Tensor.reshape           Tensor.reshape_25        1 1 99 107 shape=(1,128,20,20) $input=99 #99=(1,2,64,400)f32 #107=(1,128,20,20)f32
nn.Conv2d                model.10.m.0.attn.pe.conv 1 1 107 108 bias=True dilation=(1,1) groups=128 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,1,3,3)f32 #107=(1,128,20,20)f32 #108=(1,128,20,20)f32
pnnx.Expression          pnnx_expr_177            2 1 106 108 109 expr=add(@0,@1) #106=(1,128,20,20)f32 #108=(1,128,20,20)f32 #109=(1,128,20,20)f32
nn.Conv2d                model.10.m.0.attn.proj.conv 1 1 109 110 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,1,1)f32 #109=(1,128,20,20)f32 #110=(1,128,20,20)f32
pnnx.Expression          pnnx_expr_176            2 1 94 110 111 expr=add(@0,@1) #94=(1,128,20,20)f32 #110=(1,128,20,20)f32 #111=(1,128,20,20)f32
nn.Conv2d                model.10.m.0.ffn.0.conv  1 1 111 112 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,128,1,1)f32 #111=(1,128,20,20)f32 #112=(1,256,20,20)f32
nn.SiLU                  pnnx_unique_34           1 1 112 113 #112=(1,256,20,20)f32 #113=(1,256,20,20)f32
nn.Conv2d                model.10.m.0.ffn.1.conv  1 1 113 114 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,256,1,1)f32 #113=(1,256,20,20)f32 #114=(1,128,20,20)f32
pnnx.Expression          pnnx_expr_174            2 1 111 114 115 expr=add(@0,@1) #111=(1,128,20,20)f32 #114=(1,128,20,20)f32 #115=(1,128,20,20)f32
torch.cat                torch.cat_47             2 1 93 115 116 dim=1 #93=(1,128,20,20)f32 #115=(1,128,20,20)f32 #116=(1,256,20,20)f32
nn.Conv2d                model.10.cv2.conv        1 1 116 117 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,256,1,1)f32 #116=(1,256,20,20)f32 #117=(1,256,20,20)f32
nn.SiLU                  pnnx_unique_35           1 1 117 118 #117=(1,256,20,20)f32 #118=(1,256,20,20)f32
nn.Upsample              model.11                 1 1 118 119 mode=nearest scale_factor=(2.0,2.0) size=None #118=(1,256,20,20)f32 #119=(1,256,40,40)f32
torch.cat                torch.cat_48             2 1 119 56 120 dim=1 #119=(1,256,40,40)f32 #56=(1,128,40,40)f32 #120=(1,384,40,40)f32
nn.Conv2d                model.13.cv1.conv        1 1 120 121 bias=True dilation=(1,1) groups=1 in_channels=384 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,384,1,1)f32 #120=(1,384,40,40)f32 #121=(1,128,40,40)f32
nn.SiLU                  pnnx_unique_36           1 1 121 122 #121=(1,128,40,40)f32 #122=(1,128,40,40)f32
torch.chunk              torch.chunk_69           1 2 122 123 124 chunks=2 dim=1 $input=122 #122=(1,128,40,40)f32 #123=(1,64,40,40)f32 #124=(1,64,40,40)f32
nn.Conv2d                model.13.m.0.cv1.conv    1 1 124 125 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=32 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,64,1,1)f32 #124=(1,64,40,40)f32 #125=(1,32,40,40)f32
nn.SiLU                  pnnx_unique_37           1 1 125 126 #125=(1,32,40,40)f32 #126=(1,32,40,40)f32
nn.Conv2d                model.13.m.0.m.0.cv1.conv 1 1 126 127 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,32,3,3)f32 #126=(1,32,40,40)f32 #127=(1,32,40,40)f32
nn.SiLU                  pnnx_unique_38           1 1 127 128 #127=(1,32,40,40)f32 #128=(1,32,40,40)f32
nn.Conv2d                model.13.m.0.m.0.cv2.conv 1 1 128 129 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,32,3,3)f32 #128=(1,32,40,40)f32 #129=(1,32,40,40)f32
nn.SiLU                  pnnx_unique_39           1 1 129 130 #129=(1,32,40,40)f32 #130=(1,32,40,40)f32
pnnx.Expression          pnnx_expr_167            2 1 126 130 131 expr=add(@0,@1) #126=(1,32,40,40)f32 #130=(1,32,40,40)f32 #131=(1,32,40,40)f32
nn.Conv2d                model.13.m.0.m.1.cv1.conv 1 1 131 132 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,32,3,3)f32 #131=(1,32,40,40)f32 #132=(1,32,40,40)f32
nn.SiLU                  pnnx_unique_40           1 1 132 133 #132=(1,32,40,40)f32 #133=(1,32,40,40)f32
nn.Conv2d                model.13.m.0.m.1.cv2.conv 1 1 133 134 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,32,3,3)f32 #133=(1,32,40,40)f32 #134=(1,32,40,40)f32
nn.SiLU                  pnnx_unique_41           1 1 134 135 #134=(1,32,40,40)f32 #135=(1,32,40,40)f32
pnnx.Expression          pnnx_expr_165            2 1 131 135 136 expr=add(@0,@1) #131=(1,32,40,40)f32 #135=(1,32,40,40)f32 #136=(1,32,40,40)f32
nn.Conv2d                model.13.m.0.cv2.conv    1 1 124 137 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=32 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,64,1,1)f32 #124=(1,64,40,40)f32 #137=(1,32,40,40)f32
nn.SiLU                  pnnx_unique_42           1 1 137 138 #137=(1,32,40,40)f32 #138=(1,32,40,40)f32
torch.cat                torch.cat_49             2 1 136 138 139 dim=1 #136=(1,32,40,40)f32 #138=(1,32,40,40)f32 #139=(1,64,40,40)f32
nn.Conv2d                model.13.m.0.cv3.conv    1 1 139 140 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,1,1)f32 #139=(1,64,40,40)f32 #140=(1,64,40,40)f32
nn.SiLU                  pnnx_unique_43           1 1 140 141 #140=(1,64,40,40)f32 #141=(1,64,40,40)f32
torch.cat                torch.cat_50             3 1 123 124 141 142 dim=1 #123=(1,64,40,40)f32 #124=(1,64,40,40)f32 #141=(1,64,40,40)f32 #142=(1,192,40,40)f32
nn.Conv2d                model.13.cv2.conv        1 1 142 143 bias=True dilation=(1,1) groups=1 in_channels=192 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,192,1,1)f32 #142=(1,192,40,40)f32 #143=(1,128,40,40)f32
nn.SiLU                  pnnx_unique_44           1 1 143 144 #143=(1,128,40,40)f32 #144=(1,128,40,40)f32
nn.Upsample              model.14                 1 1 144 145 mode=nearest scale_factor=(2.0,2.0) size=None #144=(1,128,40,40)f32 #145=(1,128,80,80)f32
torch.cat                torch.cat_51             2 1 145 30 146 dim=1 #145=(1,128,80,80)f32 #30=(1,128,80,80)f32 #146=(1,256,80,80)f32
nn.Conv2d                model.16.cv1.conv        1 1 146 147 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,256,1,1)f32 #146=(1,256,80,80)f32 #147=(1,64,80,80)f32
nn.SiLU                  pnnx_unique_45           1 1 147 148 #147=(1,64,80,80)f32 #148=(1,64,80,80)f32
torch.chunk              torch.chunk_70           1 2 148 149 150 chunks=2 dim=1 $input=148 #148=(1,64,80,80)f32 #149=(1,32,80,80)f32 #150=(1,32,80,80)f32
nn.Conv2d                model.16.m.0.cv1.conv    1 1 150 151 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(1,1) out_channels=16 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(16)f32 @weight=(16,32,1,1)f32 #150=(1,32,80,80)f32 #151=(1,16,80,80)f32
nn.SiLU                  pnnx_unique_46           1 1 151 152 #151=(1,16,80,80)f32 #152=(1,16,80,80)f32
nn.Conv2d                model.16.m.0.m.0.cv1.conv 1 1 152 153 bias=True dilation=(1,1) groups=1 in_channels=16 kernel_size=(3,3) out_channels=16 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(16)f32 @weight=(16,16,3,3)f32 #152=(1,16,80,80)f32 #153=(1,16,80,80)f32
nn.SiLU                  pnnx_unique_47           1 1 153 154 #153=(1,16,80,80)f32 #154=(1,16,80,80)f32
nn.Conv2d                model.16.m.0.m.0.cv2.conv 1 1 154 155 bias=True dilation=(1,1) groups=1 in_channels=16 kernel_size=(3,3) out_channels=16 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(16)f32 @weight=(16,16,3,3)f32 #154=(1,16,80,80)f32 #155=(1,16,80,80)f32
nn.SiLU                  pnnx_unique_48           1 1 155 156 #155=(1,16,80,80)f32 #156=(1,16,80,80)f32
pnnx.Expression          pnnx_expr_158            2 1 152 156 157 expr=add(@0,@1) #152=(1,16,80,80)f32 #156=(1,16,80,80)f32 #157=(1,16,80,80)f32
nn.Conv2d                model.16.m.0.m.1.cv1.conv 1 1 157 158 bias=True dilation=(1,1) groups=1 in_channels=16 kernel_size=(3,3) out_channels=16 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(16)f32 @weight=(16,16,3,3)f32 #157=(1,16,80,80)f32 #158=(1,16,80,80)f32
nn.SiLU                  pnnx_unique_49           1 1 158 159 #158=(1,16,80,80)f32 #159=(1,16,80,80)f32
nn.Conv2d                model.16.m.0.m.1.cv2.conv 1 1 159 160 bias=True dilation=(1,1) groups=1 in_channels=16 kernel_size=(3,3) out_channels=16 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(16)f32 @weight=(16,16,3,3)f32 #159=(1,16,80,80)f32 #160=(1,16,80,80)f32
nn.SiLU                  pnnx_unique_50           1 1 160 161 #160=(1,16,80,80)f32 #161=(1,16,80,80)f32
pnnx.Expression          pnnx_expr_156            2 1 157 161 162 expr=add(@0,@1) #157=(1,16,80,80)f32 #161=(1,16,80,80)f32 #162=(1,16,80,80)f32
nn.Conv2d                model.16.m.0.cv2.conv    1 1 150 163 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(1,1) out_channels=16 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(16)f32 @weight=(16,32,1,1)f32 #150=(1,32,80,80)f32 #163=(1,16,80,80)f32
nn.SiLU                  pnnx_unique_51           1 1 163 164 #163=(1,16,80,80)f32 #164=(1,16,80,80)f32
torch.cat                torch.cat_52             2 1 162 164 165 dim=1 #162=(1,16,80,80)f32 #164=(1,16,80,80)f32 #165=(1,32,80,80)f32
nn.Conv2d                model.16.m.0.cv3.conv    1 1 165 166 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(1,1) out_channels=32 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,32,1,1)f32 #165=(1,32,80,80)f32 #166=(1,32,80,80)f32
nn.SiLU                  pnnx_unique_52           1 1 166 167 #166=(1,32,80,80)f32 #167=(1,32,80,80)f32
torch.cat                torch.cat_53             3 1 149 150 167 168 dim=1 #149=(1,32,80,80)f32 #150=(1,32,80,80)f32 #167=(1,32,80,80)f32 #168=(1,96,80,80)f32
nn.Conv2d                model.16.cv2.conv        1 1 168 169 bias=True dilation=(1,1) groups=1 in_channels=96 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,96,1,1)f32 #168=(1,96,80,80)f32 #169=(1,64,80,80)f32
nn.SiLU                  pnnx_unique_53           1 1 169 170 #169=(1,64,80,80)f32 #170=(1,64,80,80)f32
nn.Conv2d                model.17.conv            1 1 170 171 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(64)f32 @weight=(64,64,3,3)f32 #170=(1,64,80,80)f32 #171=(1,64,40,40)f32
nn.SiLU                  pnnx_unique_54           1 1 171 172 #171=(1,64,40,40)f32 #172=(1,64,40,40)f32
torch.cat                torch.cat_54             2 1 172 144 173 dim=1 #172=(1,64,40,40)f32 #144=(1,128,40,40)f32 #173=(1,192,40,40)f32
nn.Conv2d                model.19.cv1.conv        1 1 173 174 bias=True dilation=(1,1) groups=1 in_channels=192 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,192,1,1)f32 #173=(1,192,40,40)f32 #174=(1,128,40,40)f32
nn.SiLU                  pnnx_unique_55           1 1 174 175 #174=(1,128,40,40)f32 #175=(1,128,40,40)f32
torch.chunk              torch.chunk_71           1 2 175 176 177 chunks=2 dim=1 $input=175 #175=(1,128,40,40)f32 #176=(1,64,40,40)f32 #177=(1,64,40,40)f32
nn.Conv2d                model.19.m.0.cv1.conv    1 1 177 178 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=32 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,64,1,1)f32 #177=(1,64,40,40)f32 #178=(1,32,40,40)f32
nn.SiLU                  pnnx_unique_56           1 1 178 179 #178=(1,32,40,40)f32 #179=(1,32,40,40)f32
nn.Conv2d                model.19.m.0.m.0.cv1.conv 1 1 179 180 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,32,3,3)f32 #179=(1,32,40,40)f32 #180=(1,32,40,40)f32
nn.SiLU                  pnnx_unique_57           1 1 180 181 #180=(1,32,40,40)f32 #181=(1,32,40,40)f32
nn.Conv2d                model.19.m.0.m.0.cv2.conv 1 1 181 182 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,32,3,3)f32 #181=(1,32,40,40)f32 #182=(1,32,40,40)f32
nn.SiLU                  pnnx_unique_58           1 1 182 183 #182=(1,32,40,40)f32 #183=(1,32,40,40)f32
pnnx.Expression          pnnx_expr_149            2 1 179 183 184 expr=add(@0,@1) #179=(1,32,40,40)f32 #183=(1,32,40,40)f32 #184=(1,32,40,40)f32
nn.Conv2d                model.19.m.0.m.1.cv1.conv 1 1 184 185 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,32,3,3)f32 #184=(1,32,40,40)f32 #185=(1,32,40,40)f32
nn.SiLU                  pnnx_unique_59           1 1 185 186 #185=(1,32,40,40)f32 #186=(1,32,40,40)f32
nn.Conv2d                model.19.m.0.m.1.cv2.conv 1 1 186 187 bias=True dilation=(1,1) groups=1 in_channels=32 kernel_size=(3,3) out_channels=32 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,32,3,3)f32 #186=(1,32,40,40)f32 #187=(1,32,40,40)f32
nn.SiLU                  pnnx_unique_60           1 1 187 188 #187=(1,32,40,40)f32 #188=(1,32,40,40)f32
pnnx.Expression          pnnx_expr_147            2 1 184 188 189 expr=add(@0,@1) #184=(1,32,40,40)f32 #188=(1,32,40,40)f32 #189=(1,32,40,40)f32
nn.Conv2d                model.19.m.0.cv2.conv    1 1 177 190 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=32 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(32)f32 @weight=(32,64,1,1)f32 #177=(1,64,40,40)f32 #190=(1,32,40,40)f32
nn.SiLU                  pnnx_unique_61           1 1 190 191 #190=(1,32,40,40)f32 #191=(1,32,40,40)f32
torch.cat                torch.cat_55             2 1 189 191 192 dim=1 #189=(1,32,40,40)f32 #191=(1,32,40,40)f32 #192=(1,64,40,40)f32
nn.Conv2d                model.19.m.0.cv3.conv    1 1 192 193 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=64 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,64,1,1)f32 #192=(1,64,40,40)f32 #193=(1,64,40,40)f32
nn.SiLU                  pnnx_unique_62           1 1 193 194 #193=(1,64,40,40)f32 #194=(1,64,40,40)f32
torch.cat                torch.cat_56             3 1 176 177 194 195 dim=1 #176=(1,64,40,40)f32 #177=(1,64,40,40)f32 #194=(1,64,40,40)f32 #195=(1,192,40,40)f32
nn.Conv2d                model.19.cv2.conv        1 1 195 196 bias=True dilation=(1,1) groups=1 in_channels=192 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,192,1,1)f32 #195=(1,192,40,40)f32 #196=(1,128,40,40)f32
nn.SiLU                  pnnx_unique_63           1 1 196 197 #196=(1,128,40,40)f32 #197=(1,128,40,40)f32
nn.Conv2d                model.20.conv            1 1 197 198 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(2,2) @bias=(128)f32 @weight=(128,128,3,3)f32 #197=(1,128,40,40)f32 #198=(1,128,20,20)f32
nn.SiLU                  pnnx_unique_64           1 1 198 199 #198=(1,128,20,20)f32 #199=(1,128,20,20)f32
torch.cat                torch.cat_57             2 1 199 118 200 dim=1 #199=(1,128,20,20)f32 #118=(1,256,20,20)f32 #200=(1,384,20,20)f32
nn.Conv2d                model.22.cv1.conv        1 1 200 201 bias=True dilation=(1,1) groups=1 in_channels=384 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,384,1,1)f32 #200=(1,384,20,20)f32 #201=(1,256,20,20)f32
nn.SiLU                  pnnx_unique_65           1 1 201 202 #201=(1,256,20,20)f32 #202=(1,256,20,20)f32
torch.chunk              torch.chunk_72           1 2 202 203 204 chunks=2 dim=1 $input=202 #202=(1,256,20,20)f32 #203=(1,128,20,20)f32 #204=(1,128,20,20)f32
nn.Conv2d                model.22.m.0.0.cv1.conv  1 1 204 205 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,128,3,3)f32 #204=(1,128,20,20)f32 #205=(1,64,20,20)f32
nn.SiLU                  pnnx_unique_66           1 1 205 206 #205=(1,64,20,20)f32 #206=(1,64,20,20)f32
nn.Conv2d                model.22.m.0.0.cv2.conv  1 1 206 207 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,64,3,3)f32 #206=(1,64,20,20)f32 #207=(1,128,20,20)f32
nn.SiLU                  pnnx_unique_67           1 1 207 208 #207=(1,128,20,20)f32 #208=(1,128,20,20)f32
pnnx.Expression          pnnx_expr_141            2 1 204 208 209 expr=add(@0,@1) #204=(1,128,20,20)f32 #208=(1,128,20,20)f32 #209=(1,128,20,20)f32
nn.Conv2d                model.22.m.0.1.attn.qkv.conv 1 1 209 210 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,128,1,1)f32 #209=(1,128,20,20)f32 #210=(1,256,20,20)f32
Tensor.view              Tensor.view_29           1 1 210 211 shape=(1,2,128,400) $input=210 #210=(1,256,20,20)f32 #211=(1,2,128,400)f32
torch.split              torch.split_76           1 3 211 212 213 214 dim=2 split_size_or_sections=(32,32,64) $tensor=211 #211=(1,2,128,400)f32 #212=(1,2,32,400)f32 #213=(1,2,32,400)f32 #214=(1,2,64,400)f32
torch.transpose          torch.transpose_82       1 1 212 215 dim0=-2 dim1=-1 $input=212 #212=(1,2,32,400)f32 #215=(1,2,400,32)f32
torch.matmul             torch.matmul_92          2 1 215 213 216 $input=215 $other=213 #215=(1,2,400,32)f32 #213=(1,2,32,400)f32 #216=(1,2,400,400)f32
pnnx.Expression          pnnx_expr_119            1 1 216 217 expr=mul(@0,0.17677669) #216=(1,2,400,400)f32 #217=(1,2,400,400)f32
F.softmax                F.softmax_96             1 1 217 218 dim=-1 $input=217 #217=(1,2,400,400)f32 #218=(1,2,400,400)f32
torch.transpose          torch.transpose_83       1 1 218 219 dim0=-2 dim1=-1 $input=218 #218=(1,2,400,400)f32 #219=(1,2,400,400)f32
torch.matmul             torch.matmul_93          2 1 214 219 220 $input=214 $other=219 #214=(1,2,64,400)f32 #219=(1,2,400,400)f32 #220=(1,2,64,400)f32
Tensor.view              Tensor.view_30           1 1 220 221 shape=(1,128,20,20) $input=220 #220=(1,2,64,400)f32 #221=(1,128,20,20)f32
Tensor.reshape           Tensor.reshape_26        1 1 214 222 shape=(1,128,20,20) $input=214 #214=(1,2,64,400)f32 #222=(1,128,20,20)f32
nn.Conv2d                model.22.m.0.1.attn.pe.conv 1 1 222 223 bias=True dilation=(1,1) groups=128 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,1,3,3)f32 #222=(1,128,20,20)f32 #223=(1,128,20,20)f32
pnnx.Expression          pnnx_expr_113            2 1 221 223 224 expr=add(@0,@1) #221=(1,128,20,20)f32 #223=(1,128,20,20)f32 #224=(1,128,20,20)f32
nn.Conv2d                model.22.m.0.1.attn.proj.conv 1 1 224 225 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,128,1,1)f32 #224=(1,128,20,20)f32 #225=(1,128,20,20)f32
pnnx.Expression          pnnx_expr_112            2 1 209 225 226 expr=add(@0,@1) #209=(1,128,20,20)f32 #225=(1,128,20,20)f32 #226=(1,128,20,20)f32
nn.Conv2d                model.22.m.0.1.ffn.0.conv 1 1 226 227 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,128,1,1)f32 #226=(1,128,20,20)f32 #227=(1,256,20,20)f32
nn.SiLU                  pnnx_unique_68           1 1 227 228 #227=(1,256,20,20)f32 #228=(1,256,20,20)f32
nn.Conv2d                model.22.m.0.1.ffn.1.conv 1 1 228 229 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=128 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,256,1,1)f32 #228=(1,256,20,20)f32 #229=(1,128,20,20)f32
pnnx.Expression          pnnx_expr_110            2 1 226 229 230 expr=add(@0,@1) #226=(1,128,20,20)f32 #229=(1,128,20,20)f32 #230=(1,128,20,20)f32
torch.cat                torch.cat_58             3 1 203 204 230 231 dim=1 #203=(1,128,20,20)f32 #204=(1,128,20,20)f32 #230=(1,128,20,20)f32 #231=(1,384,20,20)f32
nn.Conv2d                model.22.cv2.conv        1 1 231 232 bias=True dilation=(1,1) groups=1 in_channels=384 kernel_size=(1,1) out_channels=256 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,384,1,1)f32 #231=(1,384,20,20)f32 #232=(1,256,20,20)f32
nn.SiLU                  pnnx_unique_69           1 1 232 233 #232=(1,256,20,20)f32 #233=(1,256,20,20)f32
nn.Conv2d                model.23.one2one_cv2.0.0.conv 1 1 170 234 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(3,3) out_channels=16 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(16)f32 @weight=(16,64,3,3)f32 #170=(1,64,80,80)f32 #234=(1,16,80,80)f32
nn.SiLU                  model.23.one2one_cv2.2.1.act 1 1 234 235 #234=(1,16,80,80)f32 #235=(1,16,80,80)f32
nn.Conv2d                model.23.one2one_cv2.0.1.conv 1 1 235 236 bias=True dilation=(1,1) groups=1 in_channels=16 kernel_size=(3,3) out_channels=16 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(16)f32 @weight=(16,16,3,3)f32 #235=(1,16,80,80)f32 #236=(1,16,80,80)f32
nn.SiLU                  pnnx_unique_70           1 1 236 237 #236=(1,16,80,80)f32 #237=(1,16,80,80)f32
nn.Conv2d                model.23.one2one_cv2.0.2 1 1 237 238 bias=True dilation=(1,1) groups=1 in_channels=16 kernel_size=(1,1) out_channels=4 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(4)f32 @weight=(4,16,1,1)f32 #237=(1,16,80,80)f32 #238=(1,4,80,80)f32
Tensor.view              Tensor.view_31           1 1 238 239 shape=(1,4,6400) $input=238 #238=(1,4,80,80)f32 #239=(1,4,6400)f32
nn.Conv2d                model.23.one2one_cv2.1.0.conv 1 1 197 240 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(3,3) out_channels=16 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(16)f32 @weight=(16,128,3,3)f32 #197=(1,128,40,40)f32 #240=(1,16,40,40)f32
nn.SiLU                  pnnx_unique_71           1 1 240 241 #240=(1,16,40,40)f32 #241=(1,16,40,40)f32
nn.Conv2d                model.23.one2one_cv2.1.1.conv 1 1 241 242 bias=True dilation=(1,1) groups=1 in_channels=16 kernel_size=(3,3) out_channels=16 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(16)f32 @weight=(16,16,3,3)f32 #241=(1,16,40,40)f32 #242=(1,16,40,40)f32
nn.SiLU                  pnnx_unique_72           1 1 242 243 #242=(1,16,40,40)f32 #243=(1,16,40,40)f32
nn.Conv2d                model.23.one2one_cv2.1.2 1 1 243 244 bias=True dilation=(1,1) groups=1 in_channels=16 kernel_size=(1,1) out_channels=4 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(4)f32 @weight=(4,16,1,1)f32 #243=(1,16,40,40)f32 #244=(1,4,40,40)f32
Tensor.view              Tensor.view_32           1 1 244 245 shape=(1,4,1600) $input=244 #244=(1,4,40,40)f32 #245=(1,4,1600)f32
nn.Conv2d                model.23.one2one_cv2.2.0.conv 1 1 233 246 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(3,3) out_channels=16 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(16)f32 @weight=(16,256,3,3)f32 #233=(1,256,20,20)f32 #246=(1,16,20,20)f32
nn.SiLU                  pnnx_unique_73           1 1 246 247 #246=(1,16,20,20)f32 #247=(1,16,20,20)f32
nn.Conv2d                model.23.one2one_cv2.2.1.conv 1 1 247 248 bias=True dilation=(1,1) groups=1 in_channels=16 kernel_size=(3,3) out_channels=16 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(16)f32 @weight=(16,16,3,3)f32 #247=(1,16,20,20)f32 #248=(1,16,20,20)f32
nn.SiLU                  pnnx_unique_74           1 1 248 249 #248=(1,16,20,20)f32 #249=(1,16,20,20)f32
nn.Conv2d                model.23.one2one_cv2.2.2 1 1 249 250 bias=True dilation=(1,1) groups=1 in_channels=16 kernel_size=(1,1) out_channels=4 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(4)f32 @weight=(4,16,1,1)f32 #249=(1,16,20,20)f32 #250=(1,4,20,20)f32
Tensor.view              Tensor.view_33           1 1 250 251 shape=(1,4,400) $input=250 #250=(1,4,20,20)f32 #251=(1,4,400)f32
torch.cat                torch.cat_59             3 1 239 245 251 252 dim=-1 #239=(1,4,6400)f32 #245=(1,4,1600)f32 #251=(1,4,400)f32 #252=(1,4,8400)f32
nn.Conv2d                model.23.one2one_cv3.0.0.0.conv 1 1 170 253 bias=True dilation=(1,1) groups=64 in_channels=64 kernel_size=(3,3) out_channels=64 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(64)f32 @weight=(64,1,3,3)f32 #170=(1,64,80,80)f32 #253=(1,64,80,80)f32
nn.SiLU                  model.23.one2one_cv3.2.1.1.act 1 1 253 254 #253=(1,64,80,80)f32 #254=(1,64,80,80)f32
nn.Conv2d                model.23.one2one_cv3.0.0.1.conv 1 1 254 255 bias=True dilation=(1,1) groups=1 in_channels=64 kernel_size=(1,1) out_channels=80 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(80)f32 @weight=(80,64,1,1)f32 #254=(1,64,80,80)f32 #255=(1,80,80,80)f32
nn.SiLU                  pnnx_unique_75           1 1 255 256 #255=(1,80,80,80)f32 #256=(1,80,80,80)f32
nn.Conv2d                model.23.one2one_cv3.0.1.0.conv 1 1 256 257 bias=True dilation=(1,1) groups=80 in_channels=80 kernel_size=(3,3) out_channels=80 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(80)f32 @weight=(80,1,3,3)f32 #256=(1,80,80,80)f32 #257=(1,80,80,80)f32
nn.SiLU                  pnnx_unique_76           1 1 257 258 #257=(1,80,80,80)f32 #258=(1,80,80,80)f32
nn.Conv2d                model.23.one2one_cv3.0.1.1.conv 1 1 258 259 bias=True dilation=(1,1) groups=1 in_channels=80 kernel_size=(1,1) out_channels=80 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(80)f32 @weight=(80,80,1,1)f32 #258=(1,80,80,80)f32 #259=(1,80,80,80)f32
nn.SiLU                  pnnx_unique_77           1 1 259 260 #259=(1,80,80,80)f32 #260=(1,80,80,80)f32
nn.Conv2d                model.23.one2one_cv3.0.2 1 1 260 261 bias=True dilation=(1,1) groups=1 in_channels=80 kernel_size=(1,1) out_channels=80 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(80)f32 @weight=(80,80,1,1)f32 #260=(1,80,80,80)f32 #261=(1,80,80,80)f32
Tensor.view              Tensor.view_34           1 1 261 262 shape=(1,80,6400) $input=261 #261=(1,80,80,80)f32 #262=(1,80,6400)f32
nn.Conv2d                model.23.one2one_cv3.1.0.0.conv 1 1 197 263 bias=True dilation=(1,1) groups=128 in_channels=128 kernel_size=(3,3) out_channels=128 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(128)f32 @weight=(128,1,3,3)f32 #197=(1,128,40,40)f32 #263=(1,128,40,40)f32
nn.SiLU                  pnnx_unique_78           1 1 263 264 #263=(1,128,40,40)f32 #264=(1,128,40,40)f32
nn.Conv2d                model.23.one2one_cv3.1.0.1.conv 1 1 264 265 bias=True dilation=(1,1) groups=1 in_channels=128 kernel_size=(1,1) out_channels=80 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(80)f32 @weight=(80,128,1,1)f32 #264=(1,128,40,40)f32 #265=(1,80,40,40)f32
nn.SiLU                  pnnx_unique_79           1 1 265 266 #265=(1,80,40,40)f32 #266=(1,80,40,40)f32
nn.Conv2d                model.23.one2one_cv3.1.1.0.conv 1 1 266 267 bias=True dilation=(1,1) groups=80 in_channels=80 kernel_size=(3,3) out_channels=80 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(80)f32 @weight=(80,1,3,3)f32 #266=(1,80,40,40)f32 #267=(1,80,40,40)f32
nn.SiLU                  pnnx_unique_80           1 1 267 268 #267=(1,80,40,40)f32 #268=(1,80,40,40)f32
nn.Conv2d                model.23.one2one_cv3.1.1.1.conv 1 1 268 269 bias=True dilation=(1,1) groups=1 in_channels=80 kernel_size=(1,1) out_channels=80 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(80)f32 @weight=(80,80,1,1)f32 #268=(1,80,40,40)f32 #269=(1,80,40,40)f32
nn.SiLU                  pnnx_unique_81           1 1 269 270 #269=(1,80,40,40)f32 #270=(1,80,40,40)f32
nn.Conv2d                model.23.one2one_cv3.1.2 1 1 270 271 bias=True dilation=(1,1) groups=1 in_channels=80 kernel_size=(1,1) out_channels=80 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(80)f32 @weight=(80,80,1,1)f32 #270=(1,80,40,40)f32 #271=(1,80,40,40)f32
Tensor.view              Tensor.view_35           1 1 271 272 shape=(1,80,1600) $input=271 #271=(1,80,40,40)f32 #272=(1,80,1600)f32
nn.Conv2d                model.23.one2one_cv3.2.0.0.conv 1 1 233 273 bias=True dilation=(1,1) groups=256 in_channels=256 kernel_size=(3,3) out_channels=256 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(256)f32 @weight=(256,1,3,3)f32 #233=(1,256,20,20)f32 #273=(1,256,20,20)f32
nn.SiLU                  pnnx_unique_82           1 1 273 274 #273=(1,256,20,20)f32 #274=(1,256,20,20)f32
nn.Conv2d                model.23.one2one_cv3.2.0.1.conv 1 1 274 275 bias=True dilation=(1,1) groups=1 in_channels=256 kernel_size=(1,1) out_channels=80 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(80)f32 @weight=(80,256,1,1)f32 #274=(1,256,20,20)f32 #275=(1,80,20,20)f32
nn.SiLU                  pnnx_unique_83           1 1 275 276 #275=(1,80,20,20)f32 #276=(1,80,20,20)f32
nn.Conv2d                model.23.one2one_cv3.2.1.0.conv 1 1 276 277 bias=True dilation=(1,1) groups=80 in_channels=80 kernel_size=(3,3) out_channels=80 padding=(1,1) padding_mode=zeros stride=(1,1) @bias=(80)f32 @weight=(80,1,3,3)f32 #276=(1,80,20,20)f32 #277=(1,80,20,20)f32
nn.SiLU                  pnnx_unique_84           1 1 277 278 #277=(1,80,20,20)f32 #278=(1,80,20,20)f32
nn.Conv2d                model.23.one2one_cv3.2.1.1.conv 1 1 278 279 bias=True dilation=(1,1) groups=1 in_channels=80 kernel_size=(1,1) out_channels=80 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(80)f32 @weight=(80,80,1,1)f32 #278=(1,80,20,20)f32 #279=(1,80,20,20)f32
nn.SiLU                  pnnx_unique_85           1 1 279 280 #279=(1,80,20,20)f32 #280=(1,80,20,20)f32
nn.Conv2d                model.23.one2one_cv3.2.2 1 1 280 281 bias=True dilation=(1,1) groups=1 in_channels=80 kernel_size=(1,1) out_channels=80 padding=(0,0) padding_mode=zeros stride=(1,1) @bias=(80)f32 @weight=(80,80,1,1)f32 #280=(1,80,20,20)f32 #281=(1,80,20,20)f32
Tensor.view              Tensor.view_36           1 1 281 282 shape=(1,80,400) $input=281 #281=(1,80,20,20)f32 #282=(1,80,400)f32
torch.cat                torch.cat_60             3 1 262 272 282 283 dim=-1 #262=(1,80,6400)f32 #272=(1,80,1600)f32 #282=(1,80,400)f32 #283=(1,80,8400)f32
pnnx.Attribute           pnnx_fold_1038           0 1 284 @data=(1,8400)f32 #284=(1,8400)f32
pnnx.Attribute           pnnx_fold_anchor_points.1 0 1 285 @data=(1,2,8400)f32 #285=(1,2,8400)f32
pnnx.Attribute           pnnx_fold_anchor_points.1_1 0 1 286 @data=(1,2,8400)f32 #286=(1,2,8400)f32
torch.chunk              torch.chunk_73           1 2 252 287 288 chunks=2 dim=1 $input=252 #252=(1,4,8400)f32 #287=(1,2,8400)f32 #288=(1,2,8400)f32
pnnx.Expression          pnnx_expr_6              2 1 285 287 289 expr=sub(@0,@1) #285=(1,2,8400)f32 #287=(1,2,8400)f32 #289=(1,2,8400)f32
pnnx.Expression          pnnx_expr_4              2 1 286 288 290 expr=add(@0,@1) #286=(1,2,8400)f32 #288=(1,2,8400)f32 #290=(1,2,8400)f32
torch.cat                torch.cat_63             2 1 289 290 291 dim=1 #289=(1,2,8400)f32 #290=(1,2,8400)f32 #291=(1,4,8400)f32
pnnx.Expression          pnnx_expr_2              2 1 291 284 292 expr=mul(@0,@1) #291=(1,4,8400)f32 #284=(1,8400)f32 #292=(1,4,8400)f32
F.sigmoid                F.sigmoid_94             1 1 283 293 $input=283 #283=(1,80,8400)f32 #293=(1,80,8400)f32
torch.cat                torch.cat_64             2 1 292 293 294 dim=1 #292=(1,4,8400)f32 #293=(1,80,8400)f32 #294=(1,84,8400)f32
Tensor.permute           Tensor.permute_24        1 1 294 295 dims=(0,2,1) $input=294 #294=(1,84,8400)f32 #295=(1,8400,84)f32
pnnx.Output              pnnx_output_0            1 0 295 #295=(1,8400,84)f32
